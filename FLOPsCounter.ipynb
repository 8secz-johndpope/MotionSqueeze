{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thop import profile\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from opts import parser\n",
    "import os, sys, argparse\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname('..'))))\n",
    "from manjin_models import TSN\n",
    "from resnet_TSM import matching_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainFolder=\"net_runs\"\n",
    "subFolder=\"TSM_matchflow_consecutive_segment_resnet18_something_run16\"\n",
    "snap_pref=\"TSM_resnet\"\n",
    "\n",
    "train_path=\"data/something_train.txt\"\n",
    "val_path=\"data/something_val.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name=\"something\"\n",
    "netType1=\"TSM\"\n",
    "netType2=\"TSM_resnet50\"\n",
    "netType3=\"TSM_flow\"\n",
    "netType4=\"TSM_flow_resnet50\"\n",
    "netType5=\"I3D\"\n",
    "netType6=\"I3D_flow\"\n",
    "batch_size=1\n",
    "learning_rate=0.01\n",
    "num_segments_8=8\n",
    "num_segments_16=16\n",
    "num_segments_32=32\n",
    "num_segments_128=128\n",
    "mode=1\n",
    "dropout=0.0\n",
    "iter_size=1\n",
    "num_workers=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = torch.rand(num_segments_8,3,224,224).cuda()\n",
    "input2 = torch.rand(num_segments_16,3,224,224).cuda()\n",
    "input3 = torch.rand(num_segments_32,3,224,224).cuda()\n",
    "input4 = torch.rand(num_segments_128,3,224,224).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['main.py', dataset_name, 'RGB', train_path, val_path, '--arch',\n",
    "            str(netType1), '--num_segments', str(num_segments_8), '--mode', str(mode),\n",
    "            '--gd', '200', '--lr', str(learning_rate), '--lr_steps',\n",
    "            '20', '30', '--epochs', '35', '-b', str(batch_size), '-i',\n",
    "            str(iter_size), '-j', str(num_workers), '--dropout',\n",
    "            str(dropout),\n",
    "            '--consensus_type', 'avg', '--eval-freq', '1', '--rgb_prefix', 'img_',\n",
    "            '--pretrained_parts', 'finetune', '--no_partialbn',\n",
    "            '-p', '20', '--nesterov', 'True']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "TSM Configurations:\n",
      "- dataset: something\n",
      "- modality: RGB\n",
      "- train_list: data/something_train.txt\n",
      "- val_list: data/something_val.txt\n",
      "- arch: TSM\n",
      "- num_segments: 8\n",
      "- mode: 1\n",
      "- consensus_type: avg\n",
      "- pretrained_parts: finetune\n",
      "- k: 3\n",
      "- dropout: 0.0\n",
      "- loss_type: nll\n",
      "- rep_flow: False\n",
      "- epochs: 35\n",
      "- batch_size: 1\n",
      "- iter_size: 1\n",
      "- lr: 0.01\n",
      "- lr_steps: [20.0, 30.0]\n",
      "- momentum: 0.9\n",
      "- weight_decay: 0.0005\n",
      "- clip_gradient: 200.0\n",
      "- no_partialbn: True\n",
      "- nesterov: True\n",
      "- num_long_cycles: 0\n",
      "- num_short_cycles: 0\n",
      "- last_cycle_tune: False\n",
      "- print_freq: 20\n",
      "- eval_freq: 1\n",
      "- workers: 5\n",
      "- resume: \n",
      "- evaluate: False\n",
      "- snapshot_pref: \n",
      "- val_output_folder: \n",
      "- start_epoch: 0\n",
      "- gpus: None\n",
      "- flow_prefix: img_\n",
      "- rgb_prefix: img_\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "args_dict = args.__dict__\n",
    "print(\"------------------------------------\")\n",
    "print(args.arch+\" Configurations:\")\n",
    "for key in args_dict.keys():\n",
    "    print(\"- {}: {}\".format(key, args_dict[key]))\n",
    "print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dataset == 'ucf101':\n",
    "    num_class = 101\n",
    "    rgb_read_format = \"{:05d}.jpg\"\n",
    "elif args.dataset == 'hmdb51':\n",
    "    num_class = 51\n",
    "    rgb_read_format = \"{:05d}.jpg\"        \n",
    "elif args.dataset == 'kinetics':\n",
    "    num_class = 400\n",
    "    rgb_read_format = \"{:05d}.jpg\"\n",
    "elif args.dataset == 'something':\n",
    "    num_class = 174\n",
    "    rgb_read_format = \"{:05d}.jpg\"\n",
    "elif args.dataset == 'tinykinetics':\n",
    "    num_class = 150\n",
    "    rgb_read_format = \"{:05d}.jpg\"        \n",
    "else:\n",
    "    raise ValueError('Unknown dataset '+args.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing TSN with base model: TSM.\n",
      "TSN Configurations:\n",
      "    input_modality:     RGB\n",
      "    num_segments:       8\n",
      "    new_length:         1\n",
      "    consensus_module:   avg\n",
      "    dropout_ratio:      0.0\n",
      "    representation flow:      False\n",
      "        \n",
      "conv1.weight layer has pretrained weights\n",
      "bn1.running_mean layer has pretrained weights\n",
      "bn1.running_var layer has pretrained weights\n",
      "bn1.weight layer has pretrained weights\n",
      "bn1.bias layer has pretrained weights\n",
      "layer1.0.conv1.weight layer has pretrained weights\n",
      "layer1.0.bn1.running_mean layer has pretrained weights\n",
      "layer1.0.bn1.running_var layer has pretrained weights\n",
      "layer1.0.bn1.weight layer has pretrained weights\n",
      "layer1.0.bn1.bias layer has pretrained weights\n",
      "layer1.0.conv2.weight layer has pretrained weights\n",
      "layer1.0.bn2.running_mean layer has pretrained weights\n",
      "layer1.0.bn2.running_var layer has pretrained weights\n",
      "layer1.0.bn2.weight layer has pretrained weights\n",
      "layer1.0.bn2.bias layer has pretrained weights\n",
      "layer1.1.conv1.weight layer has pretrained weights\n",
      "layer1.1.bn1.running_mean layer has pretrained weights\n",
      "layer1.1.bn1.running_var layer has pretrained weights\n",
      "layer1.1.bn1.weight layer has pretrained weights\n",
      "layer1.1.bn1.bias layer has pretrained weights\n",
      "layer1.1.conv2.weight layer has pretrained weights\n",
      "layer1.1.bn2.running_mean layer has pretrained weights\n",
      "layer1.1.bn2.running_var layer has pretrained weights\n",
      "layer1.1.bn2.weight layer has pretrained weights\n",
      "layer1.1.bn2.bias layer has pretrained weights\n",
      "layer2.0.conv1.weight layer has pretrained weights\n",
      "layer2.0.bn1.running_mean layer has pretrained weights\n",
      "layer2.0.bn1.running_var layer has pretrained weights\n",
      "layer2.0.bn1.weight layer has pretrained weights\n",
      "layer2.0.bn1.bias layer has pretrained weights\n",
      "layer2.0.conv2.weight layer has pretrained weights\n",
      "layer2.0.bn2.running_mean layer has pretrained weights\n",
      "layer2.0.bn2.running_var layer has pretrained weights\n",
      "layer2.0.bn2.weight layer has pretrained weights\n",
      "layer2.0.bn2.bias layer has pretrained weights\n",
      "layer2.0.downsample.0.weight layer has pretrained weights\n",
      "layer2.0.downsample.1.running_mean layer has pretrained weights\n",
      "layer2.0.downsample.1.running_var layer has pretrained weights\n",
      "layer2.0.downsample.1.weight layer has pretrained weights\n",
      "layer2.0.downsample.1.bias layer has pretrained weights\n",
      "layer2.1.conv1.weight layer has pretrained weights\n",
      "layer2.1.bn1.running_mean layer has pretrained weights\n",
      "layer2.1.bn1.running_var layer has pretrained weights\n",
      "layer2.1.bn1.weight layer has pretrained weights\n",
      "layer2.1.bn1.bias layer has pretrained weights\n",
      "layer2.1.conv2.weight layer has pretrained weights\n",
      "layer2.1.bn2.running_mean layer has pretrained weights\n",
      "layer2.1.bn2.running_var layer has pretrained weights\n",
      "layer2.1.bn2.weight layer has pretrained weights\n",
      "layer2.1.bn2.bias layer has pretrained weights\n",
      "layer3.0.conv1.weight layer has pretrained weights\n",
      "layer3.0.bn1.running_mean layer has pretrained weights\n",
      "layer3.0.bn1.running_var layer has pretrained weights\n",
      "layer3.0.bn1.weight layer has pretrained weights\n",
      "layer3.0.bn1.bias layer has pretrained weights\n",
      "layer3.0.conv2.weight layer has pretrained weights\n",
      "layer3.0.bn2.running_mean layer has pretrained weights\n",
      "layer3.0.bn2.running_var layer has pretrained weights\n",
      "layer3.0.bn2.weight layer has pretrained weights\n",
      "layer3.0.bn2.bias layer has pretrained weights\n",
      "layer3.0.downsample.0.weight layer has pretrained weights\n",
      "layer3.0.downsample.1.running_mean layer has pretrained weights\n",
      "layer3.0.downsample.1.running_var layer has pretrained weights\n",
      "layer3.0.downsample.1.weight layer has pretrained weights\n",
      "layer3.0.downsample.1.bias layer has pretrained weights\n",
      "layer3.1.conv1.weight layer has pretrained weights\n",
      "layer3.1.bn1.running_mean layer has pretrained weights\n",
      "layer3.1.bn1.running_var layer has pretrained weights\n",
      "layer3.1.bn1.weight layer has pretrained weights\n",
      "layer3.1.bn1.bias layer has pretrained weights\n",
      "layer3.1.conv2.weight layer has pretrained weights\n",
      "layer3.1.bn2.running_mean layer has pretrained weights\n",
      "layer3.1.bn2.running_var layer has pretrained weights\n",
      "layer3.1.bn2.weight layer has pretrained weights\n",
      "layer3.1.bn2.bias layer has pretrained weights\n",
      "layer4.0.conv1.weight layer has pretrained weights\n",
      "layer4.0.bn1.running_mean layer has pretrained weights\n",
      "layer4.0.bn1.running_var layer has pretrained weights\n",
      "layer4.0.bn1.weight layer has pretrained weights\n",
      "layer4.0.bn1.bias layer has pretrained weights\n",
      "layer4.0.conv2.weight layer has pretrained weights\n",
      "layer4.0.bn2.running_mean layer has pretrained weights\n",
      "layer4.0.bn2.running_var layer has pretrained weights\n",
      "layer4.0.bn2.weight layer has pretrained weights\n",
      "layer4.0.bn2.bias layer has pretrained weights\n",
      "layer4.0.downsample.0.weight layer has pretrained weights\n",
      "layer4.0.downsample.1.running_mean layer has pretrained weights\n",
      "layer4.0.downsample.1.running_var layer has pretrained weights\n",
      "layer4.0.downsample.1.weight layer has pretrained weights\n",
      "layer4.0.downsample.1.bias layer has pretrained weights\n",
      "layer4.1.conv1.weight layer has pretrained weights\n",
      "layer4.1.bn1.running_mean layer has pretrained weights\n",
      "layer4.1.bn1.running_var layer has pretrained weights\n",
      "layer4.1.bn1.weight layer has pretrained weights\n",
      "layer4.1.bn1.bias layer has pretrained weights\n",
      "layer4.1.conv2.weight layer has pretrained weights\n",
      "layer4.1.bn2.running_mean layer has pretrained weights\n",
      "layer4.1.bn2.running_var layer has pretrained weights\n",
      "layer4.1.bn2.weight layer has pretrained weights\n",
      "layer4.1.bn2.bias layer has pretrained weights\n",
      "Imagenet feature extractor: OFF\n",
      "\n",
      "Initializing TSN with base model: TSM_flow.\n",
      "TSN Configurations:\n",
      "    input_modality:     RGB\n",
      "    num_segments:       8\n",
      "    new_length:         1\n",
      "    consensus_module:   avg\n",
      "    dropout_ratio:      0.0\n",
      "    representation flow:      False\n",
      "        \n",
      "conv1.weight layer has pretrained weights\n",
      "bn1.running_mean layer has pretrained weights\n",
      "bn1.running_var layer has pretrained weights\n",
      "bn1.weight layer has pretrained weights\n",
      "bn1.bias layer has pretrained weights\n",
      "layer1.0.conv1.weight layer has pretrained weights\n",
      "layer1.0.bn1.running_mean layer has pretrained weights\n",
      "layer1.0.bn1.running_var layer has pretrained weights\n",
      "layer1.0.bn1.weight layer has pretrained weights\n",
      "layer1.0.bn1.bias layer has pretrained weights\n",
      "layer1.0.conv2.weight layer has pretrained weights\n",
      "layer1.0.bn2.running_mean layer has pretrained weights\n",
      "layer1.0.bn2.running_var layer has pretrained weights\n",
      "layer1.0.bn2.weight layer has pretrained weights\n",
      "layer1.0.bn2.bias layer has pretrained weights\n",
      "layer1.1.conv1.weight layer has pretrained weights\n",
      "layer1.1.bn1.running_mean layer has pretrained weights\n",
      "layer1.1.bn1.running_var layer has pretrained weights\n",
      "layer1.1.bn1.weight layer has pretrained weights\n",
      "layer1.1.bn1.bias layer has pretrained weights\n",
      "layer1.1.conv2.weight layer has pretrained weights\n",
      "layer1.1.bn2.running_mean layer has pretrained weights\n",
      "layer1.1.bn2.running_var layer has pretrained weights\n",
      "layer1.1.bn2.weight layer has pretrained weights\n",
      "layer1.1.bn2.bias layer has pretrained weights\n",
      "layer2.0.conv1.weight layer has pretrained weights\n",
      "layer2.0.bn1.running_mean layer has pretrained weights\n",
      "layer2.0.bn1.running_var layer has pretrained weights\n",
      "layer2.0.bn1.weight layer has pretrained weights\n",
      "layer2.0.bn1.bias layer has pretrained weights\n",
      "layer2.0.conv2.weight layer has pretrained weights\n",
      "layer2.0.bn2.running_mean layer has pretrained weights\n",
      "layer2.0.bn2.running_var layer has pretrained weights\n",
      "layer2.0.bn2.weight layer has pretrained weights\n",
      "layer2.0.bn2.bias layer has pretrained weights\n",
      "layer2.0.downsample.0.weight layer has pretrained weights\n",
      "layer2.0.downsample.1.running_mean layer has pretrained weights\n",
      "layer2.0.downsample.1.running_var layer has pretrained weights\n",
      "layer2.0.downsample.1.weight layer has pretrained weights\n",
      "layer2.0.downsample.1.bias layer has pretrained weights\n",
      "layer2.1.conv1.weight layer has pretrained weights\n",
      "layer2.1.bn1.running_mean layer has pretrained weights\n",
      "layer2.1.bn1.running_var layer has pretrained weights\n",
      "layer2.1.bn1.weight layer has pretrained weights\n",
      "layer2.1.bn1.bias layer has pretrained weights\n",
      "layer2.1.conv2.weight layer has pretrained weights\n",
      "layer2.1.bn2.running_mean layer has pretrained weights\n",
      "layer2.1.bn2.running_var layer has pretrained weights\n",
      "layer2.1.bn2.weight layer has pretrained weights\n",
      "layer2.1.bn2.bias layer has pretrained weights\n",
      "layer3.0.conv1.weight layer has pretrained weights\n",
      "layer3.0.bn1.running_mean layer has pretrained weights\n",
      "layer3.0.bn1.running_var layer has pretrained weights\n",
      "layer3.0.bn1.weight layer has pretrained weights\n",
      "layer3.0.bn1.bias layer has pretrained weights\n",
      "layer3.0.conv2.weight layer has pretrained weights\n",
      "layer3.0.bn2.running_mean layer has pretrained weights\n",
      "layer3.0.bn2.running_var layer has pretrained weights\n",
      "layer3.0.bn2.weight layer has pretrained weights\n",
      "layer3.0.bn2.bias layer has pretrained weights\n",
      "layer3.0.downsample.0.weight layer has pretrained weights\n",
      "layer3.0.downsample.1.running_mean layer has pretrained weights\n",
      "layer3.0.downsample.1.running_var layer has pretrained weights\n",
      "layer3.0.downsample.1.weight layer has pretrained weights\n",
      "layer3.0.downsample.1.bias layer has pretrained weights\n",
      "layer3.1.conv1.weight layer has pretrained weights\n",
      "layer3.1.bn1.running_mean layer has pretrained weights\n",
      "layer3.1.bn1.running_var layer has pretrained weights\n",
      "layer3.1.bn1.weight layer has pretrained weights\n",
      "layer3.1.bn1.bias layer has pretrained weights\n",
      "layer3.1.conv2.weight layer has pretrained weights\n",
      "layer3.1.bn2.running_mean layer has pretrained weights\n",
      "layer3.1.bn2.running_var layer has pretrained weights\n",
      "layer3.1.bn2.weight layer has pretrained weights\n",
      "layer3.1.bn2.bias layer has pretrained weights\n",
      "layer4.0.conv1.weight layer has pretrained weights\n",
      "layer4.0.bn1.running_mean layer has pretrained weights\n",
      "layer4.0.bn1.running_var layer has pretrained weights\n",
      "layer4.0.bn1.weight layer has pretrained weights\n",
      "layer4.0.bn1.bias layer has pretrained weights\n",
      "layer4.0.conv2.weight layer has pretrained weights\n",
      "layer4.0.bn2.running_mean layer has pretrained weights\n",
      "layer4.0.bn2.running_var layer has pretrained weights\n",
      "layer4.0.bn2.weight layer has pretrained weights\n",
      "layer4.0.bn2.bias layer has pretrained weights\n",
      "layer4.0.downsample.0.weight layer has pretrained weights\n",
      "layer4.0.downsample.1.running_mean layer has pretrained weights\n",
      "layer4.0.downsample.1.running_var layer has pretrained weights\n",
      "layer4.0.downsample.1.weight layer has pretrained weights\n",
      "layer4.0.downsample.1.bias layer has pretrained weights\n",
      "layer4.1.conv1.weight layer has pretrained weights\n",
      "layer4.1.bn1.running_mean layer has pretrained weights\n",
      "layer4.1.bn1.running_var layer has pretrained weights\n",
      "layer4.1.bn1.weight layer has pretrained weights\n",
      "layer4.1.bn1.bias layer has pretrained weights\n",
      "layer4.1.conv2.weight layer has pretrained weights\n",
      "layer4.1.bn2.running_mean layer has pretrained weights\n",
      "layer4.1.bn2.running_var layer has pretrained weights\n",
      "layer4.1.bn2.weight layer has pretrained weights\n",
      "layer4.1.bn2.bias layer has pretrained weights\n",
      "Imagenet feature extractor: OFF\n"
     ]
    }
   ],
   "source": [
    "model1 = TSN(num_class, args.num_segments, args.pretrained_parts, args.modality,\n",
    "                base_model=netType1,\n",
    "                consensus_type=args.consensus_type, dropout=args.dropout, partial_bn=not args.no_partialbn).cuda()\n",
    "# model2 = TSN(num_class, args.num_segments, args.pretrained_parts, args.modality,\n",
    "#                 base_model=netType2,\n",
    "#                 consensus_type=args.consensus_type, dropout=args.dropout, partial_bn=not args.no_partialbn).cuda()\n",
    "model3 = TSN(num_class, args.num_segments, args.pretrained_parts, args.modality,\n",
    "                base_model=netType3,\n",
    "                consensus_type=args.consensus_type, dropout=args.dropout, partial_bn=not args.no_partialbn).cuda()\n",
    "# model4 = TSN(num_class, args.num_segments, args.pretrained_parts, args.modality,\n",
    "#                 base_model=netType4,\n",
    "#                 consensus_type=args.consensus_type, dropout=args.dropout, partial_bn=not args.no_partialbn).cuda()\n",
    "# model9 = TSN(num_class, args.num_segments, args.pretrained_parts, args.modality,\n",
    "#                 base_model=netType5,\n",
    "#                 consensus_type=args.consensus_type, dropout=args.dropout, partial_bn=not args.no_partialbn).cuda()\n",
    "# model10 = TSN(num_class, args.num_segments, args.pretrained_parts, args.modality,\n",
    "#                 base_model=netType6,\n",
    "#                 consensus_type=args.consensus_type, dropout=args.dropout, partial_bn=not args.no_partialbn).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.num_segments=num_segments_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model5 = TSN(num_class, args.num_segments, args.pretrained_parts, args.modality,\n",
    "#                 base_model=netType1,\n",
    "#                 consensus_type=args.consensus_type, dropout=args.dropout, partial_bn=not args.no_partialbn).cuda()\n",
    "# model6 = TSN(num_class, args.num_segments, args.pretrained_parts, args.modality,\n",
    "#                 base_model=netType2,\n",
    "#                 consensus_type=args.consensus_type, dropout=args.dropout, partial_bn=not args.no_partialbn).cuda()\n",
    "# model7 = TSN(num_class, args.num_segments, args.pretrained_parts, args.modality,\n",
    "#                 base_model=netType3,\n",
    "#                 consensus_type=args.consensus_type, dropout=args.dropout, partial_bn=not args.no_partialbn).cuda()\n",
    "# model8 = TSN(num_class, args.num_segments, args.pretrained_parts, args.modality,\n",
    "#                 base_model=netType4,\n",
    "#                 consensus_type=args.consensus_type, dropout=args.dropout, partial_bn=not args.no_partialbn).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.num_segments=num_segments_32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model9 = TSN(num_class, args.num_segments, args.pretrained_parts, args.modality,\n",
    "#                 base_model=netType2,\n",
    "#                 consensus_type=args.consensus_type, dropout=args.dropout, partial_bn=not args.no_partialbn).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.num_segments=num_segments_128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model10 = TSN(num_class, args.num_segments, args.pretrained_parts, args.modality,\n",
    "#                 base_model=netType2,\n",
    "#                 consensus_type=args.consensus_type, dropout=args.dropout, partial_bn=not args.no_partialbn).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature\n",
    "increase = pow(1.05, 30)\n",
    "temperature = 10 * increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No BN layer Freezing.\n",
      "No BN layer Freezing.\n",
      "No BN layer Freezing.\n",
      "Register FLOP counter for module Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module ReLU(inplace)\n",
      "Register FLOP counter for module Sigmoid()\n",
      "Register FLOP counter for module MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "Register FLOP counter for module Softmax()\n",
      "Register FLOP counter for module ReLU()\n",
      "Register FLOP counter for module SpatialCorrelationSampler()\n",
      "Register FLOP counter for module Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module ReLU()\n",
      "Register FLOP counter for module Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module ReLU()\n",
      "Register FLOP counter for module Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module ReLU()\n",
      "Register FLOP counter for module Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module ReLU()\n",
      "Register FLOP counter for module Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module ReLU()\n",
      "Register FLOP counter for module Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module ReLU()\n",
      "Register FLOP counter for module Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module ReLU()\n",
      "Register FLOP counter for module Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module ReLU()\n",
      "Register FLOP counter for module Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module ReLU()\n",
      "Register FLOP counter for module Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module ReLU()\n",
      "Register FLOP counter for module Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module ReLU()\n",
      "Register FLOP counter for module Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module ReLU()\n",
      "Register FLOP counter for module Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module ReLU(inplace)\n",
      "Register FLOP counter for module Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module ReLU()\n",
      "Register FLOP counter for module Softmax()\n",
      "Register FLOP counter for module Softmax()\n",
      "Register FLOP counter for module Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module ReLU(inplace)\n",
      "Register FLOP counter for module Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module ReLU(inplace)\n",
      "Register FLOP counter for module Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module ReLU(inplace)\n",
      "Register FLOP counter for module Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module ReLU(inplace)\n",
      "Register FLOP counter for module Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module ReLU(inplace)\n",
      "Register FLOP counter for module Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module ReLU(inplace)\n",
      "Register FLOP counter for module Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module ReLU(inplace)\n",
      "Register FLOP counter for module Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module ReLU(inplace)\n",
      "Register FLOP counter for module Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "Register FLOP counter for module BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Register FLOP counter for module AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "Register FLOP counter for module Linear(in_features=512, out_features=174, bias=True)\n",
      "Register FLOP counter for module ConsensusModule()\n",
      "No BN layer Freezing.\n"
     ]
    }
   ],
   "source": [
    "flops1, params1 = profile(model1, inputs=(input1, temperature, 1), verbose=False)\n",
    "# flops2, params2 = profile(model2, inputs=(input1, temperature, ), verbose=False)\n",
    "flops3, params3 = profile(model3, inputs=(input1, temperature, 1), verbose=True)\n",
    "# flops4, params4 = profile(model4, inputs=(input1, temperature, ), verbose=False)\n",
    "# flops5, params5 = profile(model5, inputs=(input2, temperature, ), verbose=False)\n",
    "# flops6, params6 = profile(model6, inputs=(input2, temperature, ), verbose=False)\n",
    "# flops7, params7 = profile(model7, inputs=(input2, temperature, ), verbose=False)\n",
    "# flops8, params8 = profile(model8, inputs=(input2, temperature, ), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flops9, params9 = profile(model9, inputs=(input1, temperature, ), verbose=False)\n",
    "# flops10, params10 = profile(model10, inputs=(input1, temperature, ), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_format(num):\n",
    "    magnitude = 0\n",
    "    while abs(num) >= 1000:\n",
    "        magnitude += 1\n",
    "        num /= 1000.0\n",
    "    # add more suffixes if you need them\n",
    "    return '%.4f%s' % (num, ['', 'K', 'M', 'G', 'T', 'P'][magnitude])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSM,8\t\t\tFLOPs: 14.5896G, \tParams : 11.2660M\n",
      "TSM_flow,8\t\tFLOPs: 14.9433G, \tParams : 11.2961M\n"
     ]
    }
   ],
   "source": [
    "print('%s,%d\\t\\t\\tFLOPs: %s, \\tParams : %s' % (netType1, num_segments_8, human_format(flops1), human_format(params1)))\n",
    "# print('%s,%d\\t\\tFLOPs: %s, \\tParams : %s' % (netType2, num_segments_8, human_format(flops2), human_format(params2)))\n",
    "print('%s,%d\\t\\tFLOPs: %s, \\tParams : %s' % (netType3, num_segments_8, human_format(flops3), human_format(params3)))\n",
    "# print('%s,%d\\tFLOPs: %s, \\tParams : %s' % (netType4, num_segments_8, human_format(flops4), human_format(params4)))\n",
    "# print('='*70)\n",
    "# print('%s,%d\\t\\t\\tFLOPs: %s, \\tParams : %s' % (netType1, num_segments_16, human_format(flops5), human_format(params5)))\n",
    "# print('%s,%d\\t\\tFLOPs: %s, \\tParams : %s' % (netType2, num_segments_16, human_format(flops6), human_format(params6)))\n",
    "# print('%s,%d\\t\\tFLOPs: %s, \\tParams : %s' % (netType3, num_segments_16, human_format(flops7), human_format(params7)))\n",
    "# print('%s,%d\\tFLOPs: %s, \\tParams : %s' % (netType4, num_segments_16, human_format(flops8), human_format(params8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('%s,%d\\t\\tFLOPs: %s, \\tParams : %s' % (netType2, num_segments_8, human_format(flops2), human_format(params2)))\n",
    "# print('%s,%d\\t\\tFLOPs: %s, \\tParams : %s' % (netType2, num_segments_16, human_format(flops6), human_format(params6)))\n",
    "# print('%s,%d\\t\\tFLOPs: %s, \\tParams : %s' % (netType2, num_segments_32, human_format(flops9), human_format(params9)))\n",
    "# print('%s,%d\\t\\tFLOPs: %s, \\tParams : %s' % (netType2, num_segments_128, human_format(flops10), human_format(params10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('%s,%d\\t\\tFLOPs: %s, \\tParams : %s' % (netType5, num_segments_8, human_format(flops9), human_format(params9)))\n",
    "# print('%s,%d\\t\\tFLOPs: %s, \\tParams : %s' % (netType6, num_segments_8, human_format(flops10), human_format(params10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
